{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13ee6474-8f35-4082-a66c-f7133fd336db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "import duckdb\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from helper import get_openai_api_key, get_phoenix_endpoint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "479785aa-7677-4f5c-9bc5-e6bb88985879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phoenix as px\n",
    "import os\n",
    "from phoenix.otel import register\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "from openinference.semconv.trace import SpanAttributes\n",
    "from opentelemetry.trace import Status, StatusCode\n",
    "from openinference.instrumentation import TracerProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaae0263-7c6e-42b6-89d8-a6223725b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the OpenAI client\n",
    "openai_api_key = get_openai_api_key()\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ab406b-a167-44a7-95e0-83f98bf7a41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "âš ï¸ PHOENIX_COLLECTOR_ENDPOINT is set to http://localhost:6006/.\n",
      "âš ï¸ This means that traces will be sent to the collector endpoint and not this app.\n",
      "âš ï¸ If you would like to use this app to view traces, please unset this environmentvariable via e.g. `del os.environ['PHOENIX_COLLECTOR_ENDPOINT']` \n",
      "âš ï¸ You will need to restart your notebook to apply this change.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "ðŸ“– For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "session = px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "487f0d36-0745-4909-946e-45fbdff75269",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"tracing-agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "578b31fc-556f-4f75-9b3a-3cc664ace5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”­ OpenTelemetry Tracing Details ðŸ”­\n",
      "|  Phoenix Project: tracing-agent\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: http://localhost:6006/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  âš ï¸ WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tracer_provider = register(\n",
    "    project_name=PROJECT_NAME,\n",
    "    endpoint= get_phoenix_endpoint() + \"v1/traces\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a98257b-c313-417e-a476-3c1459039ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenAIInstrumentor().instrument(tracer_provider = tracer_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91e4e01b-c45b-49b6-95c4-d7e7763d77db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer = tracer_provider.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fae79398-e39a-4166-bd8e-6cfa3ba5d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to the transactional data\n",
    "TRANSACTION_DATA_FILE_PATH = 'data/Store_Sales_Price_Elasticity_Promotions_Data.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4464030a-1b97-4266-b8db-983f9609074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template for step 2 of tool 1\n",
    "SQL_GENERATION_PROMPT = \"\"\"\n",
    "Generate an SQL query based on a prompt. Do not reply with anything besides the SQL query.\n",
    "The prompt is: {prompt}\n",
    "\n",
    "The available columns are: {columns}\n",
    "The table name is: {table_name}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e58e5bf-2e60-4ecd-900f-3caaa6f275ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for step 2 of tool 1\n",
    "def generate_sql_query(prompt: str, columns: list, table_name: str) -> str:\n",
    "    \"\"\"Generate an SQL query based on a prompt\"\"\"\n",
    "    formatted_prompt = SQL_GENERATION_PROMPT.format(prompt=prompt, \n",
    "                                                    columns=columns, \n",
    "                                                    table_name=table_name)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c71ad5e-6ce5-4210-bbd1-3864859be998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for tool 1\n",
    "@tracer.tool()\n",
    "def lookup_sales_data(prompt: str) -> str:\n",
    "    \"\"\"Implementation of sales data lookup from parquet file using SQL\"\"\"\n",
    "    try:\n",
    "\n",
    "        # define the table name\n",
    "        table_name = \"sales\"\n",
    "        \n",
    "        # step 1: read the parquet file into a DuckDB table\n",
    "        df = pd.read_parquet(TRANSACTION_DATA_FILE_PATH)\n",
    "        duckdb.sql(f\"CREATE TABLE IF NOT EXISTS {table_name} AS SELECT * FROM df\")\n",
    "\n",
    "        # step 2: generate the SQL code\n",
    "        sql_query = generate_sql_query(prompt, df.columns, table_name)\n",
    "        # clean the response to make sure it only includes the SQL code\n",
    "        sql_query = sql_query.strip()\n",
    "        sql_query = sql_query.replace(\"```sql\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "        with tracer.start_as_current_span(\n",
    "            \"execute_sql_query\", \n",
    "            openinference_span_kind=\"chain\"\n",
    "        ) as span:\n",
    "            span.set_input(sql_query)\n",
    "            # step 3: execute the SQL query\n",
    "            result = duckdb.sql(sql_query).df()\n",
    "            span.set_output(value=str(result))\n",
    "            span.set_status(StatusCode.OK)\n",
    "        \n",
    "        return result.to_string()\n",
    "    except Exception as e:\n",
    "        return f\"Error accessing data: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16cfc01-5692-4f57-bea6-7d2fd47e7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct prompt based on analysis type and data subset\n",
    "DATA_ANALYSIS_PROMPT = \"\"\"\n",
    "Analyze the following data: {data}\n",
    "Your job is to answer the following question: {prompt}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b9e2098-8562-4abe-a285-46d6683cc090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for tool 2\n",
    "@tracer.tool()\n",
    "def analyze_sales_data(prompt: str, data: str) -> str:\n",
    "    \"\"\"Implementation of AI-powered sales data analysis\"\"\"\n",
    "    formatted_prompt = DATA_ANALYSIS_PROMPT.format(data=data, prompt=prompt)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    analysis = response.choices[0].message.content\n",
    "    return analysis if analysis else \"No analysis could be generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27e72468-9f4d-4314-8b90-2bc614d6f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template for step 1 of tool 3\n",
    "CHART_CONFIGURATION_PROMPT = \"\"\"\n",
    "Generate a chart configuration based on this data: {data}\n",
    "The goal is to show: {visualization_goal}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7f2d906-4d37-4904-b670-84105fba3d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class defining the response format of step 1 of tool 3\n",
    "class VisualizationConfig(BaseModel):\n",
    "    chart_type: str = Field(..., description=\"Type of chart to generate\")\n",
    "    x_axis: str = Field(..., description=\"Name of the x-axis column\")\n",
    "    y_axis: str = Field(..., description=\"Name of the y-axis column\")\n",
    "    title: str = Field(..., description=\"Title of the chart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db095c69-ff9d-4f75-a512-fd907a025a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for step 1 of tool 3\n",
    "@tracer.chain()\n",
    "def extract_chart_config(data: str, visualization_goal: str) -> dict:\n",
    "    \"\"\"Generate chart visualization configuration\n",
    "    \n",
    "    Args:\n",
    "        data: String containing the data to visualize\n",
    "        visualization_goal: Description of what the visualization should show\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing line chart configuration\n",
    "    \"\"\"\n",
    "    formatted_prompt = CHART_CONFIGURATION_PROMPT.format(data=data, \n",
    "                                                         visualization_goal=visualization_goal)\n",
    "    \n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "        response_format=VisualizationConfig,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Extract axis and title info from response\n",
    "        content = response.choices[0].message.content\n",
    "        \n",
    "        # Return structured chart config\n",
    "        return {\n",
    "            \"chart_type\": content.chart_type,\n",
    "            \"x_axis\": content.x_axis,\n",
    "            \"y_axis\": content.y_axis,\n",
    "            \"title\": content.title,\n",
    "            \"data\": data\n",
    "        }\n",
    "    except Exception:\n",
    "        return {\n",
    "            \"chart_type\": \"line\", \n",
    "            \"x_axis\": \"date\",\n",
    "            \"y_axis\": \"value\",\n",
    "            \"title\": visualization_goal,\n",
    "            \"data\": data\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca31cdd4-5d49-40ad-b310-4dd68ecb5130",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_CHART_PROMPT = \"\"\"\n",
    "Write python code to create a chart based on the following configuration.\n",
    "Only return the code, no other text.\n",
    "config: {config}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b30e263e-3096-489b-be26-1e78235727a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for step 2 of tool 3\n",
    "@tracer.chain()\n",
    "def create_chart(config: dict) -> str:\n",
    "    \"\"\"Create a chart based on the configuration\"\"\"\n",
    "    formatted_prompt = CREATE_CHART_PROMPT.format(config=config)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    code = response.choices[0].message.content\n",
    "    code = code.replace(\"```python\", \"\").replace(\"```\", \"\")\n",
    "    code = code.strip()\n",
    "    \n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43c5a074-fa9c-4f8a-9316-460cad07e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for tool 3\n",
    "@tracer.tool()\n",
    "def generate_visualization(data: str, visualization_goal: str) -> str:\n",
    "    \"\"\"Generate a visualization based on the data and goal\"\"\"\n",
    "    config = extract_chart_config(data, visualization_goal)\n",
    "    code = create_chart(config)\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7883336-1a3f-462c-a99e-9d01236dde32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools/functions that can be called by the model\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"lookup_sales_data\",\n",
    "            \"description\": \"Look up data from Store Sales Price Elasticity Promotions dataset\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}\n",
    "                },\n",
    "                \"required\": [\"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"analyze_sales_data\", \n",
    "            \"description\": \"Analyze sales data to extract insights\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The lookup_sales_data tool's output.\"},\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"generate_visualization\",\n",
    "            \"description\": \"Generate Python code to create data visualizations\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\", \n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The lookup_sales_data tool's output.\"},\n",
    "                    \"visualization_goal\": {\"type\": \"string\", \"description\": \"The goal of the visualization.\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"visualization_goal\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Dictionary mapping function names to their implementations\n",
    "tool_implementations = {\n",
    "    \"lookup_sales_data\": lookup_sales_data,\n",
    "    \"analyze_sales_data\": analyze_sales_data, \n",
    "    \"generate_visualization\": generate_visualization\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd8f0a03-5aa6-459d-9237-7c7e6c01177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for executing the tools returned in the model's response\n",
    "@tracer.chain()\n",
    "def handle_tool_calls(tool_calls, messages):\n",
    "    \n",
    "    for tool_call in tool_calls:   \n",
    "        function = tool_implementations[tool_call.function.name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        result = function(**function_args)\n",
    "        messages.append({\"role\": \"tool\", \n",
    "                         \"content\": result, \n",
    "                         \"tool_call_id\": tool_call.id})\n",
    "        \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc4d460d-b0f4-458c-a9f0-302a7e51a8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b137c2a4-e8ab-440b-b290-7f4ef1ed59f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(messages):\n",
    "    print(\"Running agent with messages:\", messages)\n",
    "    if isinstance(messages, str):\n",
    "        messages = [{\"role\": \"user\", \"content\": messages}]\n",
    "    if not any(\n",
    "            isinstance(message, dict) and message.get(\"role\") == \"system\" for message in messages\n",
    "        ):\n",
    "            system_prompt = {\"role\": \"system\", \"content\": SYSTEM_PROMPT}\n",
    "            messages.append(system_prompt)\n",
    "\n",
    "    while True:\n",
    "        # Router Span\n",
    "        print(\"Starting router call span\")\n",
    "        with tracer.start_as_current_span(\n",
    "            \"router_call\", openinference_span_kind=\"chain\",\n",
    "        ) as span:\n",
    "            span.set_input(value=messages)\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "            )\n",
    "            messages.append(response.choices[0].message.model_dump())\n",
    "            tool_calls = response.choices[0].message.tool_calls\n",
    "            print(\"Received response with tool calls:\", bool(tool_calls))\n",
    "            span.set_status(StatusCode.OK)\n",
    "    \n",
    "            if tool_calls:\n",
    "                print(\"Starting tool calls span\")\n",
    "                messages = handle_tool_calls(tool_calls, messages)\n",
    "                span.set_output(value=tool_calls)\n",
    "            else:\n",
    "                print(\"No tool calls, returning final response\")\n",
    "                span.set_output(value=response.choices[0].message.content)\n",
    "                return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "429478d8-a06b-4053-9f9d-3782b9bd07cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_main_span(messages):\n",
    "    print(\"Starting main span with messages:\", messages)\n",
    "    \n",
    "    with tracer.start_as_current_span(\n",
    "        \"AgentRun\", openinference_span_kind=\"agent\"\n",
    "    ) as span:\n",
    "        span.set_input(value=messages)\n",
    "        ret = run_agent(messages)\n",
    "        print(\"Main span completed with return value:\", ret)\n",
    "        span.set_output(value=ret)\n",
    "        span.set_status(StatusCode.OK)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "251ed885-ba4c-4586-a63a-d45a035757f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main span with messages: [{'role': 'user', 'content': 'Which stores did the best in 2021?'}]\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Which stores did the best in 2021?'}]\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Starting tool calls span\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Starting tool calls span\n",
      "Starting router call span\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Main span completed with return value: In 2021, the best-performing store was **Store 2970**, achieving total sales of **$84,454.33**. Here are some of the other top-performing stores:\n",
      "\n",
      "1. **Store 3300**: $63,205.33\n",
      "2. **Store 1650**: $62,152.43\n",
      "3. **Store 1540**: $58,777.02\n",
      "4. **Store 1210**: $55,435.62\n",
      "\n",
      "Store 2970 significantly outperformed all other stores, while the closest competitors (3300 and 1650) had sales figures below 75% of Store 2970's total. Overall, Store 2970 was the clear leader in sales for the year.\n"
     ]
    }
   ],
   "source": [
    "result = start_main_span([{\"role\": \"user\", \n",
    "                           \"content\": \"Which stores did the best in 2021?\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23d7afbb-e68e-4df8-a729-556370afa3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:6006/\n"
     ]
    }
   ],
   "source": [
    "print(get_phoenix_endpoint())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195a7f6-ef16-47a3-b028-a0adf77707c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
